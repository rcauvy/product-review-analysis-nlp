{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Sentiment Analysis - NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Student name: Robert Cauvy \n",
    "* Student pace: Flex\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: Claude Fried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENTS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click to jump to matching Markdown Header.*<br><br>\n",
    " \n",
    "- **[Introduction](#INTRODUCTION)<br>**\n",
    "- **[OBTAIN](#OBTAIN)**<br>\n",
    "- **[SCRUB](#SCRUB)**<br>\n",
    "- **[EXPLORE](#EXPLORE)**<br>\n",
    "- **[MODEL](#MODEL)**<br>\n",
    "- **[iNTERPRET](#iNTERPRET)**<br>\n",
    "- **[Conclusions/Recommendations](#CONCLUSIONS-&-RECOMMENDATIONS)<br>**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hired by Apple to determine which product release has the more positive sentiment and how it compared to their competitor Google who had also just released a new service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the past decade conversations have increasingly shifted towards social media. Businesses across all industries could stand to benefit from listening to these conversations about themselves and how their products and brand are perceived by they users and prospective customers. Understanding what it is that customers enjoy the most and the least about your company's products and brand is crucial to retaining your loyal customers as well as attracting new ones.\n",
    "\n",
    "When large companies announce their new product releases at conferences and keynotes, they can obtain useful market insights and feedback from public opinion. A great source to measure market reactions is the giant social media network, Twitter.\n",
    "\n",
    "In addition to analyzing tweets various machine learning models will be trained and tested to classify tweets as either positive or negative sentiments towards the companies products and services. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not easy to obtain unbiased and unfiltered feedback and opinions from the public. Understanding how the market feels about the products and services delivered by your brand in real-time can provide valuable insights that could not get captured before the ubiquity of social media. Applying human capital to track social networks is simply not a scalable solution which makes the application of Natural Language Processing and Machine Learning classifiers well suited for this business problem.\n",
    "\n",
    "The objective of this project is provide the businesses (Apple and Google) a model that identifies which tweets hold either a positive or negative sentiment about their brand or products from a corpus of tweets. Furthermore, this project will provide the stakeholders with a list of topics and keywords that most affect public perception, leaving actionable insights for future marketing and product design decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:04.179739Z",
     "start_time": "2022-02-25T20:25:56.354673Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import (CountVectorizer,TfidfTransformer, \n",
    "                                             TfidfVectorizer,ENGLISH_STOP_WORDS)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import nltk \n",
    "from nltk import TweetTokenizer, word_tokenize,wordpunct_tokenize\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:04.201011Z",
     "start_time": "2022-02-25T20:26:04.188820Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is utilizing a dataset  provided by CrowdFlower to from data.world. The dataset contains over 9,000 tweets from SXSW(South by Southwest) Conference about new product releases from Apple and Google. The tweet have been labeled as to which emotion they convey towards a particular product category or company brand based off of the language contained in the tweet.\n",
    "\n",
    "According to the provider of the dataset, humans that were tasked with labeling the sentiments of each tweet by evaluating which brand or product the tweet was about and if the tweet expressed positive, negative, or no emotion towards a brand and/or product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:33.186719Z",
     "start_time": "2022-02-25T21:03:20.431021Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## NLP Imports\n",
    "import nltk\n",
    "from nltk import FreqDist,word_tokenize,regexp_tokenize,TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:33.488896Z",
     "start_time": "2022-02-25T21:03:33.191689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9093 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/tweet_product.csv', encoding= 'unicode_escape')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:33.534745Z",
     "start_time": "2022-02-25T21:03:33.512242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_text', 'emotion_in_tweet_is_directed_at',\n",
       "       'is_there_an_emotion_directed_at_a_brand_or_product'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:33.568259Z",
     "start_time": "2022-02-25T21:03:33.554024Z"
    }
   },
   "outputs": [],
   "source": [
    "# renaming columns to reduce verbosity\n",
    "df = df.rename(columns={\"tweet_text\": \"text\", \n",
    "                   \"emotion_in_tweet_is_directed_at\": \"product\",\n",
    "                  \"is_there_an_emotion_directed_at_a_brand_or_product\":\"sentiment\"\n",
    "                  }\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:33.635874Z",
     "start_time": "2022-02-25T21:03:33.578948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "  sentiment  \n",
       "0  Negative  \n",
       "1  Positive  \n",
       "2  Positive  \n",
       "3  Negative  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning up the values in sentinemts for easier interpretability\n",
    "\n",
    "sentiment_dict = {'Positive emotion': 'Positive', 'Negative emotion': 'Negative', \n",
    "                'No emotion toward brand or product': 'Neutral', \n",
    "                \"I can't tell\": 'Unknown'}\n",
    "df['sentiment'] = df['sentiment'].map(sentiment_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:33.717455Z",
     "start_time": "2022-02-25T21:03:33.651553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       9092 non-null   object\n",
      " 1   product    3291 non-null   object\n",
      " 2   sentiment  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:33.754778Z",
     "start_time": "2022-02-25T21:03:33.723930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.',\n",
       " \"@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW\",\n",
       " '@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.',\n",
       " \"@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw\",\n",
       " \"@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a variable \"corpus\" containing all text\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "corpus = df['text'].to_list()\n",
    "\n",
    "## Preview first 5 entries \n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:33.820736Z",
     "start_time": "2022-02-25T21:03:33.776841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "df.duplicated(subset=['text'], keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:34.030579Z",
     "start_time": "2022-02-25T21:03:33.907193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Before It Even Begins, Apple Wins #SXSW {link}</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Before It Even Begins, Apple Wins #SXSW {link}</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Google to Launch Major New Social Network Call...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Google to Launch Major New Social Network Call...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I just noticed DST is coming this weekend. How...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8483</th>\n",
       "      <td>I just noticed DST is coming this weekend. How...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>Marissa Mayer: Google Will Connect the Digital...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>Marissa Mayer: Google Will Connect the Digital...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8747</th>\n",
       "      <td>Need to buy an iPad2 while I'm in Austin at #s...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Need to buy an iPad2 while I'm in Austin at #s...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>Oh. My. God. The #SXSW app for iPad is pure, u...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Oh. My. God. The #SXSW app for iPad is pure, u...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5884</th>\n",
       "      <td>RT @mention Google to Launch Major New Social ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>RT @mention Google to Launch Major New Social ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5880</th>\n",
       "      <td>RT @mention Google to Launch Major New Social ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5883</th>\n",
       "      <td>RT @mention Google to Launch Major New Social ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5879</th>\n",
       "      <td>RT @mention Google to Launch Major New Social ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5881</th>\n",
       "      <td>RT @mention Google to Launch Major New Social ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5885</th>\n",
       "      <td>RT @mention Google to Launch Major New Social ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6294</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>RT @mention RT @mention Google to Launch Major...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6546</th>\n",
       "      <td>RT @mention RT @mention Google to Launch Major...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6576</th>\n",
       "      <td>RT @mention RT @mention It's not a rumor: Appl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>RT @mention RT @mention It's not a rumor: Appl...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>RT @mention ÷¼ GO BEYOND BORDERS! ÷_ {link} ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>RT @mention ÷¼ GO BEYOND BORDERS! ÷_ {link} ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>RT @mention ÷¼ Happy Woman's Day! Make love, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5341</th>\n",
       "      <td>RT @mention ÷¼ Happy Woman's Day! Make love, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>Really enjoying the changes in Gowalla 3.0 for...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Really enjoying the changes in Gowalla 3.0 for...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>Win free iPad 2 from webdoc.com #sxsw RT</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>Win free iPad 2 from webdoc.com #sxsw RT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>Win free ipad 2 from webdoc.com #sxsw RT</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>Win free ipad 2 from webdoc.com #sxsw RT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text             product  \\\n",
       "7     #SXSW is just starting, #CTIA is around the co...             Android   \n",
       "3962  #SXSW is just starting, #CTIA is around the co...             Android   \n",
       "466      Before It Even Begins, Apple Wins #SXSW {link}               Apple   \n",
       "468      Before It Even Begins, Apple Wins #SXSW {link}               Apple   \n",
       "9     Counting down the days to #sxsw plus strong Ca...               Apple   \n",
       "2559  Counting down the days to #sxsw plus strong Ca...               Apple   \n",
       "774   Google to Launch Major New Social Network Call...                 NaN   \n",
       "776   Google to Launch Major New Social Network Call...                 NaN   \n",
       "17    I just noticed DST is coming this weekend. How...              iPhone   \n",
       "8483  I just noticed DST is coming this weekend. How...              iPhone   \n",
       "2230  Marissa Mayer: Google Will Connect the Digital...                 NaN   \n",
       "2232  Marissa Mayer: Google Will Connect the Digital...                 NaN   \n",
       "8747  Need to buy an iPad2 while I'm in Austin at #s...                iPad   \n",
       "20    Need to buy an iPad2 while I'm in Austin at #s...                iPad   \n",
       "4897  Oh. My. God. The #SXSW app for iPad is pure, u...  iPad or iPhone App   \n",
       "21    Oh. My. God. The #SXSW app for iPad is pure, u...  iPad or iPhone App   \n",
       "5884  RT @mention Google to Launch Major New Social ...                 NaN   \n",
       "5882  RT @mention Google to Launch Major New Social ...                 NaN   \n",
       "5880  RT @mention Google to Launch Major New Social ...                 NaN   \n",
       "5883  RT @mention Google to Launch Major New Social ...                 NaN   \n",
       "5879  RT @mention Google to Launch Major New Social ...                 NaN   \n",
       "5881  RT @mention Google to Launch Major New Social ...                 NaN   \n",
       "5885  RT @mention Google to Launch Major New Social ...                 NaN   \n",
       "6295  RT @mention Marissa Mayer: Google Will Connect...                 NaN   \n",
       "6293  RT @mention Marissa Mayer: Google Will Connect...              Google   \n",
       "6297  RT @mention Marissa Mayer: Google Will Connect...                 NaN   \n",
       "6299  RT @mention Marissa Mayer: Google Will Connect...                 NaN   \n",
       "6296  RT @mention Marissa Mayer: Google Will Connect...              Google   \n",
       "6294  RT @mention Marissa Mayer: Google Will Connect...                 NaN   \n",
       "6292  RT @mention Marissa Mayer: Google Will Connect...              Google   \n",
       "6298  RT @mention Marissa Mayer: Google Will Connect...              Google   \n",
       "6300  RT @mention Marissa Mayer: Google Will Connect...                 NaN   \n",
       "6544  RT @mention RT @mention Google to Launch Major...                 NaN   \n",
       "6546  RT @mention RT @mention Google to Launch Major...                 NaN   \n",
       "6576  RT @mention RT @mention It's not a rumor: Appl...                 NaN   \n",
       "6574  RT @mention RT @mention It's not a rumor: Appl...               Apple   \n",
       "5338  RT @mention ÷¼ GO BEYOND BORDERS! ÷_ {link} ...                 NaN   \n",
       "5336  RT @mention ÷¼ GO BEYOND BORDERS! ÷_ {link} ...                 NaN   \n",
       "5339  RT @mention ÷¼ Happy Woman's Day! Make love, ...                 NaN   \n",
       "5341  RT @mention ÷¼ Happy Woman's Day! Make love, ...                 NaN   \n",
       "3950  Really enjoying the changes in Gowalla 3.0 for...         Android App   \n",
       "24    Really enjoying the changes in Gowalla 3.0 for...         Android App   \n",
       "3814           Win free iPad 2 from webdoc.com #sxsw RT                iPad   \n",
       "3812           Win free iPad 2 from webdoc.com #sxsw RT                 NaN   \n",
       "3813           Win free ipad 2 from webdoc.com #sxsw RT                iPad   \n",
       "3811           Win free ipad 2 from webdoc.com #sxsw RT                 NaN   \n",
       "\n",
       "     sentiment  \n",
       "7     Positive  \n",
       "3962  Positive  \n",
       "466   Positive  \n",
       "468   Positive  \n",
       "9     Positive  \n",
       "2559  Positive  \n",
       "774    Neutral  \n",
       "776    Neutral  \n",
       "17    Negative  \n",
       "8483  Negative  \n",
       "2230   Neutral  \n",
       "2232   Neutral  \n",
       "8747  Positive  \n",
       "20    Positive  \n",
       "4897  Positive  \n",
       "21    Positive  \n",
       "5884   Neutral  \n",
       "5882   Neutral  \n",
       "5880   Neutral  \n",
       "5883   Neutral  \n",
       "5879   Neutral  \n",
       "5881   Neutral  \n",
       "5885   Neutral  \n",
       "6295   Neutral  \n",
       "6293  Positive  \n",
       "6297   Neutral  \n",
       "6299   Neutral  \n",
       "6296  Positive  \n",
       "6294   Neutral  \n",
       "6292  Positive  \n",
       "6298  Positive  \n",
       "6300   Neutral  \n",
       "6544   Neutral  \n",
       "6546   Neutral  \n",
       "6576   Neutral  \n",
       "6574  Positive  \n",
       "5338   Neutral  \n",
       "5336   Neutral  \n",
       "5339   Neutral  \n",
       "5341   Neutral  \n",
       "3950  Positive  \n",
       "24    Positive  \n",
       "3814  Positive  \n",
       "3812   Neutral  \n",
       "3813  Positive  \n",
       "3811   Neutral  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at duplicated records\n",
    "duplicates = df.duplicated(subset=['text'], keep=False)\n",
    "df.loc[duplicates.loc[duplicates==True].index].sort_values(by='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:34.104178Z",
     "start_time": "2022-02-25T21:03:34.048832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates\n",
    "df.drop_duplicates(subset=['text'], keep='first', inplace=True)\n",
    "# check for duplicates\n",
    "df.duplicated(subset=['text'], keep='first').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going through some initial scrubbing of the dataset it is time to explore some of the characteristics of the tweet data. During this EDA phase, we will inspect the class balance, distribution of tweet lengths, WordClouds and most common words for each class. \n",
    "\n",
    "Because we are working with Twitter data, we'll work with nltk's TweetTokenizer and customize  stop words to get a better view of the content of the tweets for addressing the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:34.458664Z",
     "start_time": "2022-02-25T21:03:34.444284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive', 'Neutral', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:50.289414Z",
     "start_time": "2022-02-25T21:03:50.272548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Negative', 'Positive', 'Neutral', 'Unknown')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_order = ('Negative', 'Positive',\n",
    "       'Neutral', \"Unknown\")\n",
    "\n",
    "sentiment_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:53.005413Z",
     "start_time": "2022-02-25T21:03:52.264255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Overall sentiment distribution\n",
    "sns.catplot(data=df,x='sentiment',kind='count',order=sentiment_order,aspect=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examing the class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:55.898325Z",
     "start_time": "2022-02-25T21:03:55.847715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     5373\n",
       "Positive    2968\n",
       "Negative     569\n",
       "Unknown      156\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:03:57.503981Z",
     "start_time": "2022-02-25T21:03:57.447179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     0.592654\n",
       "Positive    0.327377\n",
       "Negative    0.062762\n",
       "Unknown     0.017207\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less than half of the tweets were classified as having any emotion. Of the tweets which were tagged as having an emotion, most were coded positive. About 3,000 tweets compared to only 570 tweets that were tagged as having negative emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:04:00.091023Z",
     "start_time": "2022-02-25T21:04:00.047566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Thanks to @mention for publishing the news of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ÛÏ@mention &amp;quot;Apple has opened a pop-up st...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Just what America needs. RT @mention Google to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>The queue at the Apple Store in Austin is FOUR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Hope it's better than wave RT @mention Buzz is...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020</th>\n",
       "      <td>It's funny watching a room full of people hold...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9032</th>\n",
       "      <td>@mention yeah, we have @mention , Google has n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9037</th>\n",
       "      <td>@mention Yes, the Google presentation was not ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>&amp;quot;Do you know what Apple is really good at...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9066</th>\n",
       "      <td>How much you want to bet Apple is disproportio...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text product sentiment\n",
       "90    Thanks to @mention for publishing the news of ...     NaN   Unknown\n",
       "102   ÛÏ@mention &quot;Apple has opened a pop-up st...     NaN   Unknown\n",
       "237   Just what America needs. RT @mention Google to...     NaN   Unknown\n",
       "341   The queue at the Apple Store in Austin is FOUR...     NaN   Unknown\n",
       "368   Hope it's better than wave RT @mention Buzz is...     NaN   Unknown\n",
       "...                                                 ...     ...       ...\n",
       "9020  It's funny watching a room full of people hold...     NaN   Unknown\n",
       "9032  @mention yeah, we have @mention , Google has n...     NaN   Unknown\n",
       "9037  @mention Yes, the Google presentation was not ...     NaN   Unknown\n",
       "9058  &quot;Do you know what Apple is really good at...     NaN   Unknown\n",
       "9066  How much you want to bet Apple is disproportio...   Apple   Unknown\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['sentiment']=='Unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tweets labeled as unknown are difficult to classify without more context and could be viewed as sarcastic.\n",
    "All tweets in the corpus will need to be classified for modeling later on and the volume accounts for less than 2% of the corpus it is safe to drop these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:04:02.834975Z",
     "start_time": "2022-02-25T21:04:02.807112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     0.603030\n",
       "Positive    0.333109\n",
       "Negative    0.063861\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['sentiment']!='Unknown']\n",
    "df['sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the business problem we are looking to solve requires understanding differences between positive and negative sentiments, it is essential that posiitive and negative twwets are separated for the exploration process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:05:31.613664Z",
     "start_time": "2022-02-25T21:05:31.599705Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,8))\n",
    "# freq.plot(25);\n",
    "\n",
    "# ## Rotate \n",
    "# ax.set_xticklabels(ax.get_xticklabels(),\n",
    "#                    rotation=45,ha='right');\n",
    "# fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:05:04.263675Z",
     "start_time": "2022-02-25T21:05:04.235676Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'freq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-82869d4c5ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Get the most_common 100 and make into a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m most_common = pd.DataFrame(freq.most_common(100),\n\u001b[0m\u001b[1;32m      3\u001b[0m                            \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                  ascending=True)\n\u001b[1;32m      5\u001b[0m \u001b[0mmost_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'barh'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'freq' is not defined"
     ]
    }
   ],
   "source": [
    "# ## Get the most_common 100 and make into a dataframe\n",
    "# most_common = pd.DataFrame(freq.most_common(100),\n",
    "#                            columns=['word','count']).sort_values('count',\n",
    "#                                                                  ascending=True)\n",
    "# most_common.set_index('word').tail(25).plot(kind='barh',figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:06.973259Z",
     "start_time": "2022-02-25T20:25:56.489Z"
    }
   },
   "outputs": [],
   "source": [
    "# def plot_most_common(freq,n=25,figsize=(12,5)):\n",
    "#     most_common = pd.DataFrame(freq.most_common(n),\n",
    "#                            columns=['word','count']).sort_values('count',\n",
    "#                                                                  ascending=True)\n",
    "#     most_common.set_index('word').tail(n).plot(kind='barh',figsize=figsize)\n",
    "    \n",
    "# plot_most_common(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:06.979938Z",
     "start_time": "2022-02-25T20:25:56.497Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make a new freq dist for tweet tokens and plot most common\n",
    "tweet_freq = FreqDist(tweet_tokens)\n",
    "plot_most_common(tweet_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:06.983545Z",
     "start_time": "2022-02-25T20:25:56.509Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_df = df.loc[df['sentiment']=='Positive']\n",
    "positive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:06.987095Z",
     "start_time": "2022-02-25T20:25:56.522Z"
    }
   },
   "outputs": [],
   "source": [
    "negative_df = df.loc[df['sentiment']=='Negative']\n",
    "negative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:06:07.822363Z",
     "start_time": "2022-02-25T21:06:07.763692Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positive_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a4bf2d303271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpositive_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpositive_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'positive_df' is not defined"
     ]
    }
   ],
   "source": [
    "positive_corpus = positive_df['text'].to_list()\n",
    "positive_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:06.998044Z",
     "start_time": "2022-02-25T20:25:56.545Z"
    }
   },
   "outputs": [],
   "source": [
    "negative_corpus = negative_df['text'].to_list()\n",
    "negative_corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:06:03.683337Z",
     "start_time": "2022-02-25T21:06:03.673856Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import TweetTokenizer\n",
    "import string\n",
    "\n",
    "#Function for tokenization of tweets\n",
    "def tweets_tokenize(corpus, preserve_case=False, strip_handles=True):\n",
    "    \n",
    "    tokenizer = TweetTokenizer(preserve_case=preserve_case, \n",
    "                               strip_handles=strip_handles)\n",
    "    tokens = tokenizer.tokenize(','.join(corpus))\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:06:03.721720Z",
     "start_time": "2022-02-25T21:06:03.694064Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positive_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1becb8f6e5c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#positive tweets tokenized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpositive_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'positive_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "#positive tweets tokenized\n",
    "positive_tokens = tweets_tokenize(positive_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:04:58.968646Z",
     "start_time": "2022-02-25T21:04:58.947913Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'negative_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0548ad335c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#negative tweets tokenized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnegative_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'negative_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "#negative tweets tokenized\n",
    "negative_tokens = tweets_tokenize(negative_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.023207Z",
     "start_time": "2022-02-25T20:25:56.573Z"
    }
   },
   "outputs": [],
   "source": [
    "#checking the most common positive tokens\n",
    "from nltk import FreqDist\n",
    "freq = FreqDist(positive_tokens)\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.030235Z",
     "start_time": "2022-02-25T20:25:56.593Z"
    }
   },
   "outputs": [],
   "source": [
    "#checking the most common negative tokens\n",
    "from nltk import FreqDist\n",
    "freq = FreqDist(negative_tokens)\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are stop words and puncuations that were tokenized and will need to be removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before removing StopWords, tokens should be lemmatized to ensure the list of words are being captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.036927Z",
     "start_time": "2022-02-25T20:25:56.608Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "#Function for lemmatizating tokens\n",
    "def lemmatize_tokens(tokens_list):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_tokens = [lemmatizer.lemmatize(word) for word in tokens_list]\n",
    "    return lemma_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.045717Z",
     "start_time": "2022-02-25T20:25:56.617Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lemmatize positive tokens\n",
    "positive_tokens_lemma = lemmatize_tokens(positive_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.051862Z",
     "start_time": "2022-02-25T20:25:56.622Z"
    }
   },
   "outputs": [],
   "source": [
    "#Lemmatize negative tokens\n",
    "negative_tokens_lemma = lemmatize_tokens(negative_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation And StopWord Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.055548Z",
     "start_time": "2022-02-25T20:25:56.632Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import nltk's stopwords and add punctuation\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list += list(string.punctuation)\n",
    "#additional punctuation characters \n",
    "add_punct = ['“','”','...',\"''\",'’','``','']\n",
    "stopword_list += add_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.061083Z",
     "start_time": "2022-02-25T20:25:56.637Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to remove of StopWords\n",
    "def stopword_removal(tokens, stopword_list=stopword_list):\n",
    "    \n",
    "    #encoding tokens to remove unrecognized characters and url links\n",
    "    stopped_tokens = [w.encode('ascii','ignore').decode() for w in tokens \n",
    "                      if (w not in stopword_list) & \n",
    "                      (w.startswith('http') == False)]\n",
    "    \n",
    "    return stopped_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.064592Z",
     "start_time": "2022-02-25T20:25:56.644Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removing StopWords from lemmatized tokens\n",
    "positive_lemma_stopped = stopword_removal(positive_tokens_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.068811Z",
     "start_time": "2022-02-25T20:25:56.653Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removing StopWords from lemmatized tokens\n",
    "negative_lemma_stopped = stopword_removal(negative_tokens_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.073775Z",
     "start_time": "2022-02-25T20:25:56.660Z"
    }
   },
   "outputs": [],
   "source": [
    "#looking at the most common tokens\n",
    "freq = FreqDist(positive_lemma_stopped)\n",
    "freq.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.079368Z",
     "start_time": "2022-02-25T20:25:56.667Z"
    }
   },
   "outputs": [],
   "source": [
    "#looking at the most common tokens\n",
    "freq = FreqDist(negative_lemma_stopped)\n",
    "freq.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.085190Z",
     "start_time": "2022-02-25T20:25:56.676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Appending stopwords list\n",
    "stopword_list.extend(['rt','co','sxsw', '#sxsw', '#sxswi','link'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.088852Z",
     "start_time": "2022-02-25T20:25:56.686Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removing StopWords from lemmatized tokens\n",
    "positive_lemma_stopped = stopword_removal(positive_tokens_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.092764Z",
     "start_time": "2022-02-25T20:25:56.702Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removing StopWords from lemmatized tokens\n",
    "negative_lemma_stopped = stopword_removal(negative_tokens_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.099298Z",
     "start_time": "2022-02-25T20:25:56.716Z"
    }
   },
   "outputs": [],
   "source": [
    "#looking at the most common tokens\n",
    "freq = FreqDist(positive_lemma_stopped)\n",
    "freq.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.105265Z",
     "start_time": "2022-02-25T20:25:56.722Z"
    }
   },
   "outputs": [],
   "source": [
    "#looking at the most common tokens\n",
    "freq = FreqDist(negative_lemma_stopped)\n",
    "freq.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCloud Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.109148Z",
     "start_time": "2022-02-25T20:25:56.731Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def wordcloud_generator(tokens, collocations=False, background_color='black', \n",
    "                       colormap='Greens', display=True):\n",
    "\n",
    "    \n",
    "    # Initalize a WordCloud\n",
    "    wordcloud = WordCloud(collocations=collocations, \n",
    "                          background_color=background_color, \n",
    "                          colormap=colormap, \n",
    "                          width=500, height=300)\n",
    "\n",
    "    # Generate wordcloud from tokens\n",
    "    wordcloud.generate(','.join(tokens))\n",
    "\n",
    "    # Plot with matplotlib\n",
    "    if display:\n",
    "        plt.figure(figsize = (12, 15), facecolor = None) \n",
    "        plt.imshow(wordcloud) \n",
    "        plt.axis('off');\n",
    "        \n",
    "    return wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.113527Z",
     "start_time": "2022-02-25T20:25:56.739Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate a WordCloud for positive tweets\n",
    "positive_cloud = wordcloud_generator(positive_lemma_stopped, collocations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.118119Z",
     "start_time": "2022-02-25T20:25:56.748Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate a WordCloud for negative tweets\n",
    "negative_cloud = wordcloud_generator(negative_lemma_stopped, colormap='Reds',\n",
    "                                     collocations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.124325Z",
     "start_time": "2022-02-25T20:25:56.754Z"
    }
   },
   "outputs": [],
   "source": [
    "def wordcloud_comp(wc1, wc2):\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(30,20), ncols=2)\n",
    "    ax[0].imshow(wc1)\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    ax[1].imshow(wc2)\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.129500Z",
     "start_time": "2022-02-25T20:25:56.762Z"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_comp(positive_cloud, negative_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the brands presenting new services and  and product launches at the event appeared most in both positive and negative tweets. Let's look at WordClouds with those words added to the stop list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.135133Z",
     "start_time": "2022-02-25T20:25:56.771Z"
    }
   },
   "outputs": [],
   "source": [
    "#removing brands and products from the Wordcloud\n",
    "stopword_list_no_brands = stopword_list + ['ipad', 'ipad2','#ipad2','apple', 'google', 'iphone', \n",
    "                           '#apple','#google', '#ipad', '#iphone', 'android']\n",
    "\n",
    "positive_stopped_brands = stopword_removal(positive_tokens_lemma, stopword_list=stopword_list_no_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.139083Z",
     "start_time": "2022-02-25T20:25:56.784Z"
    }
   },
   "outputs": [],
   "source": [
    "negative_stopped_brands = stopword_removal(negative_tokens_lemma, stopword_list=stopword_list_no_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.143887Z",
     "start_time": "2022-02-25T20:25:56.789Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_cloud_no_names = wordcloud_generator(positive_stopped_brands, collocations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.150289Z",
     "start_time": "2022-02-25T20:25:56.798Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "negative_cloud_no_names = wordcloud_generator(negative_stopped_brands, \n",
    "                                              colormap='Reds',collocations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.158640Z",
     "start_time": "2022-02-25T20:25:56.804Z"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_comp(positive_cloud_no_names,negative_cloud_no_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tweet Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.170192Z",
     "start_time": "2022-02-25T20:25:56.809Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.178795Z",
     "start_time": "2022-02-25T20:25:56.817Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_finder = BigramCollocationFinder.from_words(positive_lemma_stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.188959Z",
     "start_time": "2022-02-25T20:25:56.823Z"
    }
   },
   "outputs": [],
   "source": [
    "bigrams = positive_finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.192609Z",
     "start_time": "2022-02-25T20:25:56.830Z"
    }
   },
   "outputs": [],
   "source": [
    "#top 30 bigrams\n",
    "bigrams[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Sentiments of Products/Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.198699Z",
     "start_time": "2022-02-25T20:25:56.837Z"
    }
   },
   "outputs": [],
   "source": [
    "df['product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.202209Z",
     "start_time": "2022-02-25T20:25:56.842Z"
    }
   },
   "outputs": [],
   "source": [
    "product_order = ['iPad','Apple','iPad or iPhone App','Google','iPhone',\n",
    "                 'Other Google product or service','Android App','Android',\n",
    "                 'Other Apple product or service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.207821Z",
     "start_time": "2022-02-25T20:25:56.848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Product tweet distribution\n",
    "sns.catplot(data=df,x='product',kind='count',order=product_order,aspect=3.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.212544Z",
     "start_time": "2022-02-25T20:25:56.854Z"
    }
   },
   "outputs": [],
   "source": [
    "#mapping products and services to their brand\n",
    "product_dict={'iPad': 'Apple', 'Apple': 'Apple', 'iPad or iPhone App': 'Apple', \n",
    "              'Google': 'Google', 'iPhone': 'Apple', \n",
    "              'Other Google product or service': 'Google',\n",
    "              'Android App': 'Google', 'Android': 'Google',\n",
    "              'Other Apple product or service': 'Apple'}\n",
    "\n",
    "df['brand'] = df['product'].map(product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.216797Z",
     "start_time": "2022-02-25T20:25:56.858Z"
    }
   },
   "outputs": [],
   "source": [
    "# Brand tweet distribution\n",
    "sns.catplot(data=df,x='brand',kind='count',order=['Apple', 'Google'],aspect=3.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.220457Z",
     "start_time": "2022-02-25T20:25:56.865Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(['brand','product','sentiment']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.224709Z",
     "start_time": "2022-02-25T20:25:56.873Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_words(doc):\n",
    "    tokenizer_no_strip = TweetTokenizer(strip_handles=False)\n",
    "    tokens = tokenizer_no_strip.tokenize(doc)\n",
    "    return len(tokens)\n",
    "\n",
    "df['token_count'] = df['text'].map(lambda x: count_words(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.230741Z",
     "start_time": "2022-02-25T20:25:56.879Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize distribution of tweet lengths \n",
    "with sns.plotting_context(context='talk'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.histplot(df['token_count'], color='lightblue', ax=ax)\n",
    "    ax.set_title('Distribution of Tweet Lengths')\n",
    "    ax.set_xlabel('Number of Tokens in Tweet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.235078Z",
     "start_time": "2022-02-25T20:25:56.886Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "tweet_finder = nltk.BigramCollocationFinder.from_words(stopped_tokens)\n",
    "tweets_scored = tweet_finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.238500Z",
     "start_time": "2022-02-25T20:25:56.892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a DataFrame from the Bigrams\n",
    "pd.DataFrame(tweets_scored, columns=[\"Word\",\"Freq\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.245926Z",
     "start_time": "2022-02-25T20:25:56.900Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "tweet_pmi_finder = nltk.BigramCollocationFinder.from_words(stopped_tokens)\n",
    "tweet_pmi_finder.apply_freq_filter(3)\n",
    "\n",
    "tweet_pmi_scored = tweet_pmi_finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.250244Z",
     "start_time": "2022-02-25T20:25:56.907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a DataFrame from the Bigrams with PMI\n",
    "pd.DataFrame(tweet_pmi_scored,columns=['Words','PMI']).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:07:14.650493Z",
     "start_time": "2022-02-25T21:07:14.428232Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, plot_roc_curve, plot_confusion_matrix, roc_curve\n",
    "\n",
    "def clf_eval(y_true, y_pred, X_test, X_train, clf, n_class=3):\n",
    "    \n",
    "    \n",
    "    print(f\"Training Score: {round(clf.score(X_train, y_train),2)} \\\n",
    "            Test Score:{round(clf.score(X_test, y_true),2)}\")\n",
    "    \n",
    "   \n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report\")\n",
    "    print(\"------------------------------------------\")\n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred))\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "    \n",
    "    plot_confusion_matrix(estimator=clf, X=X_test, y_true=y_true, cmap='Blues', \n",
    "                          normalize='true', ax=ax[0], \n",
    "                          display_labels=['Negative','Neutral', 'Positive'])\n",
    " \n",
    "    pred_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    " \n",
    "    try:\n",
    "        roc_curve = metrics.plot_roc_curve(clf,X_test_tf,y_test,ax=ax[1])\n",
    "        curve.ax_.grid()\n",
    "        curve.ax_.plot([0,1],[0,1],ls=':')\n",
    "        fig.tight_layout()\n",
    "    except:\n",
    "        fig.delaxes(ax[1])\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T21:16:37.529423Z",
     "start_time": "2022-02-25T21:16:37.499849Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a52263710c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "y = df['sentiment']\n",
    "X = df['text']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wirte function for pipelines\n",
    "#bagogwords/tdidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model will be used to measure how well our model performs compared to random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.265211Z",
     "start_time": "2022-02-25T20:25:56.962Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.269826Z",
     "start_time": "2022-02-25T20:25:56.978Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf_pipe = Pipeline([('vectorizer', TfidfVectorizer(tokenizer=tokenizer.tokenize, \n",
    "                                                    stop_words=stopword_list)),\n",
    "                     ('clf', DummyClassifier(random_state=42))])\n",
    "\n",
    "clf_pipe.fit(X_train, y_train)\n",
    "y_pred = clf_pipe.predict(X_test)\n",
    "clf_eval(y_test, y_pred, X_test, X_train, clf_pipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.273442Z",
     "start_time": "2022-02-25T20:25:56.999Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb_text_pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=tokenizer.tokenize, \n",
    "                                   stop_words=stopword_list)),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.277403Z",
     "start_time": "2022-02-25T20:25:57.021Z"
    }
   },
   "outputs": [],
   "source": [
    "mnb_text_pipe.fit(X_train, y_train)\n",
    "y_pred = mnb_text_pipe.predict(X_test)\n",
    "clf_eval(y_test, y_pred, X_test, X_train, mnb_text_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.281066Z",
     "start_time": "2022-02-25T20:25:57.058Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_text_pipe = Pipeline([('vectorizer', TfidfVectorizer(tokenizer=tokenizer.tokenize, \n",
    "                                   stop_words=stopword_list)), \n",
    "    ('clf', LogisticRegressionCV(solver='saga',max_iter=500, class_weight='balanced', random_state=42,n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.284496Z",
     "start_time": "2022-02-25T20:25:57.072Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_text_pipe.fit(X_train, y_train)\n",
    "y_pred = lr_text_pipe.predict(X_test)\n",
    "clf_eval(y_test, y_pred, X_test, X_train, lr_text_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.288709Z",
     "start_time": "2022-02-25T20:25:57.084Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'clf__class_weight': ['balanced'],\n",
    "              'clf__max_iter': [100, 500, 1000],\n",
    "              'clf__Cs': [[0.01], [0.1], [1]],\n",
    "              'clf__solver': ['liblinear', 'lbfgs', 'sag', 'saga']}\n",
    "\n",
    "gs = GridSearchCV(estimator=lr_text_pipe, param_grid = param_grid, \n",
    "                              scoring='recall_macro')\n",
    "\n",
    "gs.fit(X_train,  y_train)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.292845Z",
     "start_time": "2022-02-25T20:25:57.101Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuned_lr_text_pipe = Pipeline([('vectorizer', TfidfVectorizer(tokenizer=tokenizer.tokenize, \n",
    "                                   stop_words=stopword_list)), \n",
    "    ('clf', LogisticRegressionCV(solver='liblinear',\n",
    "                                 max_iter=100, \n",
    "                                 class_weight='balanced',\n",
    "                                 Cs=1,\n",
    "                                 random_state=42,\n",
    "                                 n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.299451Z",
     "start_time": "2022-02-25T20:25:57.118Z"
    }
   },
   "outputs": [],
   "source": [
    "tuned_lr_text_pipe.fit(X_train, y_train)\n",
    "y_pred = tuned_lr_text_pipe.predict(X_test)\n",
    "clf_eval(y_test, y_pred, X_test, X_train, tuned_lr_text_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.304986Z",
     "start_time": "2022-02-25T20:25:57.137Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_text_pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=tokenizer.tokenize, \n",
    "                                   stop_words=stopword_list)), \n",
    "    ('clf', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.308756Z",
     "start_time": "2022-02-25T20:25:57.149Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_text_pipe.fit(X_train, y_train)\n",
    "y_pred = rf_text_pipe.predict(X_test)\n",
    "clf_eval(y_test, y_pred, X_test, X_train, rf_text_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* How do you interpret the results?\n",
    "* How well does your model fit your data? How much better is this than your baseline model?\n",
    "* How confident are you that your results would generalize beyond the data you have?\n",
    "* How confident are you that this model would benefit the business if put into use?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.313750Z",
     "start_time": "2022-02-25T20:25:57.179Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_importance(clf_pipe, n_features, title):\n",
    "   \n",
    "    feats = clf_pipe['vectorizer'].get_feature_names()\n",
    "    coefs = clf_pipe['clf'].coef_[0]\n",
    "    \n",
    "    importance_df = pd.DataFrame(feats, columns=['Word'])\n",
    "    importance_df['Importance'] = math.e**(abs(coefs))\n",
    "    importance_df['Coefficient'] = coefs\n",
    "\n",
    "    feat_importance = importance_df.sort_values(by = [\"Importance\"], \n",
    "                                                   ascending=False).head(n_features)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15,10), ncols=2)\n",
    "    ax[0].set_title(f'Coefficients for {title}')\n",
    "    ax[0].set_ylabel('Word')\n",
    "    ax[0].set_xlabel('Coefficient')\n",
    "    sns.barplot(x='Coefficient', y='Word', palette='magma', data=feat_importance, ax=ax[0])\n",
    "\n",
    "    ax[1].set_title(f'Feature Importances for {title}')\n",
    "    ax[1].set_ylabel('Word')\n",
    "    ax[1].set_xlabel('Importance')\n",
    "    sns.barplot(x='Importance', y='Word', palette='magma', data=feat_importance, ax=ax[1])\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T20:26:07.317880Z",
     "start_time": "2022-02-25T20:25:57.186Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_importance(lr_text_pipe, 15, 'Tuned Logistic Regression Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS & RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
