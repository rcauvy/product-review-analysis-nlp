{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW OF OSEMiN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/images/OSEMN.png' width=800>\n",
    "\n",
    "<center><a href=\"https://www.kdnuggets.com/2018/02/data-science-command-line-book-exploring-data.html\"> \n",
    "    </a></center>\n",
    "\n",
    "\n",
    "> <font size=2em>The Data Science Process we'll be using during this section--OSEMiN (pronounced \"OH-sum\", rhymes with \"possum\").  This is the most straightforward of the Data Science Processes discussed so far.  **Note that during this process, just like the others, the stages often blur together.***  It is completely acceptable (and ***often a best practice!) to float back and forth** between stages as you learn new things about your problem, dataset, requirements, etc.  \n",
    "It's quite common to get to the modeling step and realize that you need to scrub your data a bit more or engineer a different feature and jump back to the \"Scrub\" stage, or go all the way back to the \"Obtain\" stage when you realize your current data isn't sufficient to solve this problem. \n",
    "As with any of these frameworks, *OSEMiN is meant to be treated as guidelines, not law. \n",
    "</font>\n",
    "\n",
    "\n",
    "### OSEMN DETAILS\n",
    "\n",
    "**OBTAIN**\n",
    "\n",
    "- This step involves understanding stakeholder requirements, gathering information on the problem, and finally sourcing data that we think will be necessary for solving this problem. \n",
    "\n",
    "**SCRUB**\n",
    "\n",
    "- During this stage, we'll focus on preprocessing our data.  Important steps such as identifying and removing null values, dealing with outliers, normalizing data, and feature engineering/feature selection are handled around this stage.  The line with this stage really blurs with the _Explore_ stage, as it is common to only realize that certain columns require cleaning or preprocessing as a result of the visualzations and explorations done during Step 3.  \n",
    "\n",
    "- Note that although technically, categorical data should be one-hot encoded during this step, in practice, it's usually done after data exploration.  This is because it is much less time-consuming to visualize and explore a few columns containing categorical data than it is to explore many different dummy columns that have been one-hot encoded. \n",
    "\n",
    "**EXPLORE**\n",
    "\n",
    "- This step focuses on getting to know the dataset you're working with. As mentioned above, this step tends to blend with the _Scrub_ step mentioned above.  During this step, you'll create visualizations to really get a feel for your dataset.  You'll focus on things such as understanding the distribution of different columns, checking for multicollinearity, and other tasks liek that.  If your project is a classification task, you may check the balance of the different classes in your dataset.  If your problem is a regression task, you may check that the dataset meets the assumptions necessary for a regression task.  \n",
    "\n",
    "- At the end of this step, you should have a dataset ready for modeling that you've thoroughly explored and are extremely familiar with.  \n",
    "\n",
    "**MODEL**\n",
    "\n",
    "- This step, as with the last two frameworks, is also pretty self-explanatory. It consists of building and tuning models using all the tools you have in your data science toolbox.  In practice, this often means defining a threshold for success, selecting machine learning algorithms to test on the project, and tuning the ones that show promise to try and increase your results.  As with the other stages, it is both common and accepted to realize something, jump back to a previous stage like _Scrub_ or _Explore_, and make some changes to see how it affects the model.  \n",
    "\n",
    "**iNTERPRET**\n",
    "\n",
    "- During this step, you'll interpret the results of your model(s), and communicate results to stakeholders.  As with the other frameworks, communication is incredibily important! During this stage, you may come to realize that further investigation is needed, or more data.  That's totally fine--figure out what's needed, go get it, and start the process over! If your results are satisfactory to all stakeholders involved, you may also go from this stage right into productionizing your model and automating processes necessary to support it.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS CHECKLIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Keep in mind that it is normal to jump between the OSEMN phases and some of them will blend together, like SCRUB and EXPLORE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **[OBTAIN](#OBTAIN)**\n",
    "    - Import data, inspect, check for datatypes to convert and null values\n",
    "    - Display header and info.\n",
    "    - Drop any unneeded columns, if known (`df.drop(['col1','col2'],axis=1,inplace=True`)\n",
    "    <br><br>\n",
    "\n",
    "\n",
    "2. **[SCRUB](#SCRUB)**\n",
    "    - Recast data types, identify outliers, check for multicollinearity, normalize data**\n",
    "    - Check and cast data types\n",
    "        - [ ] Check for #'s that are store as objects (`df.info()`,`df.describe()`)\n",
    "            - when converting to #'s, look for odd values (like many 0's), or strings that can't be converted.\n",
    "            - Decide how to deal weird/null values (`df.unique()`, `df.isna().sum()`)\n",
    "            - `df.fillna(subset=['col_with_nulls'],'fill_value')`, `df.replace()`\n",
    "        - [ ] Check for categorical variables stored as integers.\n",
    "            - May be easier to tell when you make a scatter plotm or `pd.plotting.scatter_matrix()`\n",
    "            \n",
    "    - [ ] Check for missing values  (df.isna().sum())\n",
    "        - Can drop rows or colums\n",
    "        - For missing numeric data with median or bin/convert to categorical\n",
    "        - For missing categorical data: make NaN own category OR replace with most common category\n",
    "    - [ ] Check for multicollinearity\n",
    "        - Use seaborn to make correlation matrix plot \n",
    "        - Good rule of thumb is anything over 0.75 corr is high, remove the variable that has the most correl with the largest # of variables\n",
    "    - [ ] Normalize data (may want to do after some exploring)\n",
    "        - Most popular is Z-scoring (but won't fix skew) \n",
    "        - Can log-transform to fix skewed data\n",
    "    \n",
    "    \n",
    "3. **[EXPLORE](#EXPLORE)**\n",
    "    - [ ] Check distributions, outliers, etc**\n",
    "    - [ ] Check scales, ranges (df.describe())\n",
    "    - [ ] Check histograms to get an idea of distributions (df.hist()) and data transformations to perform.\n",
    "        - Can also do kernel density estimates\n",
    "    - [ ] Use scatter plots to check for linearity and possible categorical variables (`df.plot(\"x\",\"y\")`)\n",
    "        - categoricals will look like vertical lines\n",
    "    - [ ] Use `pd.plotting.scatter_matrix(df)` to visualize possible relationships\n",
    "    - [ ] Check for linearity.\n",
    "   \n",
    "   \n",
    "4. **[MODEL](#MODEL)**\n",
    "\n",
    "    - **Fit an initial model:** \n",
    "        - Run an initial model and get results\n",
    "\n",
    "    - **Holdout validation / Train/test split**\n",
    "        - use sklearn `train_test_split`\n",
    "    \n",
    "    \n",
    "5. **[iNTERPRET](#iNTERPRET)**\n",
    "    - **Assessing the model:**\n",
    "        - Assess parameters (slope,intercept)\n",
    "        - Check if the model explains the variation in the data (RMSE, F, R_square)\n",
    "        - *Are the coeffs, slopes, intercepts in appropriate units?*\n",
    "        - *Whats the impact of collinearity? Can we ignore?*\n",
    "        <br><br>\n",
    "    - **Revise the fitted model**\n",
    "        - Multicollinearity is big issue for lin regression and cannot fully remove it\n",
    "        - Use the predictive ability of model to test it (like R2 and RMSE)\n",
    "        - Check for missed non-linearity\n",
    "        \n",
    "       \n",
    "6. **Interpret final model and draw >=3 conclusions and recommendations from dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T18:00:23.504059Z",
     "start_time": "2020-01-29T18:00:23.498461Z"
    }
   },
   "source": [
    "<div style=\"display:block;border-bottom:solid red 3px;padding:1.4em;color:red;font-size:30pt;display:inline-block;line-height:1.5em;\">\n",
    "DELETE THIS CELL AND EVERYTHING ABOVE FROM YOUR FINAL NOTEBOOK\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time:\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n",
    "* Video of 5-min Non-Technical Presentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENTS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click to jump to matching Markdown Header.*<br><br>\n",
    " \n",
    "- **[Introduction](#INTRODUCTION)<br>**\n",
    "- **[OBTAIN](#OBTAIN)**<br>\n",
    "- **[SCRUB](#SCRUB)**<br>\n",
    "- **[EXPLORE](#EXPLORE)**<br>\n",
    "- **[MODEL](#MODEL)**<br>\n",
    "- **[iNTERPRET](#iNTERPRET)**<br>\n",
    "- **[Conclusions/Recommendations](#CONCLUSIONS-&-RECOMMENDATIONS)<br>**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Explain the point of your project and what question you are trying to answer with your modeling.\n",
    "\n",
    "In the world we live in today, social media affects not only our personal lives but the day-to-day operations of businesses as well. With the world being more connected than ever, it is crucial for businesses to be able to read the public opinion about their products and brand, and adapt to changing trends as quickly as possible or even stay ahead of them. Staying connected and being in-the-know not only allows businesses to stay relevant but also provides them with opportunities to achieve and maintain financial success.\n",
    "\n",
    "One of the many applications of this idea is when large companies such as Apple or Google hold their keynotes (Apple's WWDC or Google's I/O for example) and release new products, software updates and tease upcoming changes to their services. Another is when senior leadership within these companies attend large conferences and talk about the vision of their company and provide fans with hints as to what they can expect in the future. These are golden opportunities for these companies' marketing teams to gauge interest and gather information on public opinion.\n",
    "\n",
    "One medium that companies can utilize to read public opinion is Twitter. Millions of people share their thoughts on various topics on Twitter every day, so this makes Twitter a great resource for businesses. For this project, we were hired by Apple to conduct a sentiment analysis of tweets from the SXSW (South by Southwest) Conference. Below are the questions we will be providing insights for:\n",
    "\n",
    "1. How is Apple perceived as a company during the SXSW Conference, and how does this compare to Google as one of their main competitors?\n",
    "\n",
    "2. How are Apple and Google's products and announcements perceived during the SXSW Conference? Are there specific pain points within the products that Apple should address?\n",
    "\n",
    "Additionally, we will be training and testing different machine learning models that can classify tweets based on their sentiment. Apple can leverage these models to read the public opinion and stay ahead of their competition.\n",
    "\n",
    "## Business Problem\n",
    "\n",
    "Summary of the business problem you are trying to solve, and the data questions that you plan to answer to solve them.\n",
    "\n",
    "Knowing what customers like best about your products and brand is important if you want to both retain existing customers as well as attract new ones. Likewise, knowing what customers do not like about your brand or products will illuminate areas where change may be needed, especially if your competitors do well in those areas.\n",
    "\n",
    "Customers may provide feedback directly to you in the form of responses to surveys you conduct, and voluntary product reviews. However, it can be difficult to design surveys that completely avoid response bias, and voluntary product reviews tend to skew towards more polarized opinions.\n",
    "\n",
    "Analyzing what the general public says about your brand and products on platforms such as Twitter may yield insights other methods miss. But since it would be cost- and time-prohibitive to have human beings analyze and classify large volumes of tweets, a more automated method would be needed.\n",
    "\n",
    "This analysis is a proof-of-concept to determine if a machine learning model can be trained to predict positive or negative sentiment. There are two primary objectives that an analysis leveraging machine learning would need to meet:\n",
    "\n",
    "Starting with a corpus of tweets, separate out those in which a positive or negative sentiment towards a brand or product is expressed from those in which the sentiment is either neutral, or the sentiment is not actually directed towards your brand or product.\n",
    "Provide useful or actionable insights into the keywords, topics, or concepts that drive negative versus positive sentiment.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* What are the business's pain points related to this project?\n",
    "* How did you pick the data analysis question(s) that you did?\n",
    "* Why are these questions important from a business perspective?\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Describe the data being used for this project.\n",
    "***\n",
    "Questions to consider:\n",
    "* Where did the data come from, and how do they relate to the data analysis questions?\n",
    "* What do the data represent? Who is in the sample and what variables are included?\n",
    "* What is the target variable?\n",
    "* What are the properties of the variables you intend to use?\n",
    "***\n",
    "\n",
    "\n",
    "We used a dataset from data.world provided by CrowdFlower which contains 9,093 tweets about Apple and Google from the South by Southwest (SXSW) Conference. The tweet labels were crowdsourced and reflect which emotion they convey and what product/service/company this emotion is directed at based on the content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a dataset consisting of about 9,000 tweets that were posted during a SXSW event, and most of which are related to either Apple or Google brands or products.\n",
    "\n",
    "The tweets were coded by humans, who were asked to classify them based on emotion related to brands and products. Here is the brief overview from data.world describing what the coders were asked to do:\n",
    "\n",
    "Contributors evaluated tweets about multiple brands and products. The crowd was asked if the tweet expressed positive, negative, or no emotion towards a brand and/or product. If some emotion was expressed they were also asked to say which brand or product was the target of that emotion.\n",
    "\n",
    "I did not attempt to differentiate between Google and Apple brands and products, but rather focused on a model that could identify tweets which had some sentiment towards either brand.\n",
    "\n",
    "By far the majority of tweets were labeled as having no sentiment towards a brand or product. Of those which were identified as including a sentiment, most were coded positive. Only about 500 out of 9,000 were identified as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T04:29:33.601288Z",
     "start_time": "2022-02-04T04:29:24.784146Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "\n",
    "## NLP Imports\n",
    "import nltk\n",
    "from nltk import FreqDist,word_tokenize,regexp_tokenize,TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T04:30:36.400334Z",
     "start_time": "2022-02-04T04:30:19.036310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.8.1.tar.gz (220 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from wordcloud) (1.18.5)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from wordcloud) (7.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from wordcloud) (3.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from matplotlib->wordcloud) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n",
      "Building wheels for collected packages: wordcloud\n",
      "  Building wheel for wordcloud (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/anaconda3/envs/learn-env/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-install-bco4t3mn/wordcloud/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-install-bco4t3mn/wordcloud/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-wheel-pavxpao3\n",
      "       cwd: /private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-install-bco4t3mn/wordcloud/\n",
      "  Complete output (65 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-10.9-x86_64-3.8\n",
      "  creating build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  copying wordcloud/wordcloud_cli.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  copying wordcloud/_version.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  copying wordcloud/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  copying wordcloud/tokenization.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  copying wordcloud/wordcloud.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  copying wordcloud/color_from_image.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  copying wordcloud/__main__.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  copying wordcloud/stopwords -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  copying wordcloud/DroidSansMono.ttf -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  UPDATING build/lib.macosx-10.9-x86_64-3.8/wordcloud/_version.py\n",
      "  set build/lib.macosx-10.9-x86_64-3.8/wordcloud/_version.py to '1.8.1'\n",
      "  running build_ext\n",
      "  building 'wordcloud.query_integral_image' extension\n",
      "  creating build/temp.macosx-10.9-x86_64-3.8\n",
      "  creating build/temp.macosx-10.9-x86_64-3.8/wordcloud\n",
      "  x86_64-apple-darwin13.4.0-clang -fno-strict-aliasing -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O3 -Wall -Wstrict-prototypes -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O3 -pipe -fdebug-prefix-map=${SRC_DIR}=/usr/local/src/conda/${PKG_NAME}-${PKG_VERSION} -fdebug-prefix-map=/opt/anaconda3/envs/learn-env=/usr/local/src/conda-prefix -flto -Wl,-export_dynamic -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O3 -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -isystem /opt/anaconda3/envs/learn-env/include -D_FORTIFY_SOURCE=2 -mmacosx-version-min=10.9 -isystem /opt/anaconda3/envs/learn-env/include -I/opt/anaconda3/envs/learn-env/include/python3.8 -c wordcloud/query_integral_image.c -o build/temp.macosx-10.9-x86_64-3.8/wordcloud/query_integral_image.o\n",
      "  clang-10: warning: -Wl,-export_dynamic: 'linker' input unused [-Wunused-command-line-argument]\n",
      "  wordcloud/query_integral_image.c:15710:3: warning: 'tp_print' is deprecated [-Wdeprecated-declarations]\n",
      "    0, /*tp_print*/\n",
      "    ^\n",
      "  /opt/anaconda3/envs/learn-env/include/python3.8/cpython/object.h:260:5: note: 'tp_print' has been explicitly marked deprecated here\n",
      "      Py_DEPRECATED(3.8) int (*tp_print)(PyObject *, FILE *, int);\n",
      "      ^\n",
      "  /opt/anaconda3/envs/learn-env/include/python3.8/pyport.h:515:54: note: expanded from macro 'Py_DEPRECATED'\n",
      "  #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__))\n",
      "                                                       ^\n",
      "  wordcloud/query_integral_image.c:15829:3: warning: 'tp_print' is deprecated [-Wdeprecated-declarations]\n",
      "    0, /*tp_print*/\n",
      "    ^\n",
      "  /opt/anaconda3/envs/learn-env/include/python3.8/cpython/object.h:260:5: note: 'tp_print' has been explicitly marked deprecated here\n",
      "      Py_DEPRECATED(3.8) int (*tp_print)(PyObject *, FILE *, int);\n",
      "      ^\n",
      "  /opt/anaconda3/envs/learn-env/include/python3.8/pyport.h:515:54: note: expanded from macro 'Py_DEPRECATED'\n",
      "  #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__))\n",
      "                                                       ^\n",
      "  wordcloud/query_integral_image.c:16090:3: warning: 'tp_print' is deprecated [-Wdeprecated-declarations]\n",
      "    0, /*tp_print*/\n",
      "    ^\n",
      "  /opt/anaconda3/envs/learn-env/include/python3.8/cpython/object.h:260:5: note: 'tp_print' has been explicitly marked deprecated here\n",
      "      Py_DEPRECATED(3.8) int (*tp_print)(PyObject *, FILE *, int);\n",
      "      ^\n",
      "  /opt/anaconda3/envs/learn-env/include/python3.8/pyport.h:515:54: note: expanded from macro 'Py_DEPRECATED'\n",
      "  #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__))\n",
      "                                                       ^\n",
      "  wordcloud/query_integral_image.c:16236:3: warning: 'tp_print' is deprecated [-Wdeprecated-declarations]\n",
      "    0, /*tp_print*/\n",
      "    ^\n",
      "  /opt/anaconda3/envs/learn-env/include/python3.8/cpython/object.h:260:5: note: 'tp_print' has been explicitly marked deprecated here\n",
      "      Py_DEPRECATED(3.8) int (*tp_print)(PyObject *, FILE *, int);\n",
      "      ^\n",
      "  /opt/anaconda3/envs/learn-env/include/python3.8/pyport.h:515:54: note: expanded from macro 'Py_DEPRECATED'\n",
      "  #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__))\n",
      "                                                       ^\n",
      "  4 warnings generated.\n",
      "  x86_64-apple-darwin13.4.0-clang -bundle -undefined dynamic_lookup -Wl,-pie -Wl,-headerpad_max_install_names -Wl,-dead_strip_dylibs -Wl,-rpath,/opt/anaconda3/envs/learn-env/lib -L/opt/anaconda3/envs/learn-env/lib -flto -Wl,-export_dynamic -Wl,-pie -Wl,-headerpad_max_install_names -Wl,-dead_strip_dylibs -Wl,-rpath,/opt/anaconda3/envs/learn-env/lib -L/opt/anaconda3/envs/learn-env/lib -Wl,-pie -Wl,-headerpad_max_install_names -Wl,-dead_strip_dylibs -Wl,-rpath,/opt/anaconda3/envs/learn-env/lib -L/opt/anaconda3/envs/learn-env/lib -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -isystem /opt/anaconda3/envs/learn-env/include -D_FORTIFY_SOURCE=2 -mmacosx-version-min=10.9 -isystem /opt/anaconda3/envs/learn-env/include -arch x86_64 build/temp.macosx-10.9-x86_64-3.8/wordcloud/query_integral_image.o -o build/lib.macosx-10.9-x86_64-3.8/wordcloud/query_integral_image.cpython-38-darwin.so\n",
      "  ld: warning: -pie being ignored. It is only used when linking a main executable\n",
      "  ld: unsupported tapi file type '!tapi-tbd' in YAML file '/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/lib/libSystem.tbd' for architecture x86_64\n",
      "  clang-10: error: linker command failed with exit code 1 (use -v to see invocation)\n",
      "  error: command 'x86_64-apple-darwin13.4.0-clang' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for wordcloud\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for wordcloud\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build wordcloud\n",
      "Installing collected packages: wordcloud\n",
      "    Running setup.py install for wordcloud ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/anaconda3/envs/learn-env/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-install-bco4t3mn/wordcloud/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-install-bco4t3mn/wordcloud/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-record-yaf7sxhp/install-record.txt --single-version-externally-managed --compile --install-headers /opt/anaconda3/envs/learn-env/include/python3.8/wordcloud\n",
      "         cwd: /private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-install-bco4t3mn/wordcloud/\n",
      "    Complete output (65 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.macosx-10.9-x86_64-3.8\n",
      "    creating build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    copying wordcloud/wordcloud_cli.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    copying wordcloud/_version.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    copying wordcloud/__init__.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    copying wordcloud/tokenization.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    copying wordcloud/wordcloud.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    copying wordcloud/color_from_image.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    copying wordcloud/__main__.py -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    copying wordcloud/stopwords -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    copying wordcloud/DroidSansMono.ttf -> build/lib.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    UPDATING build/lib.macosx-10.9-x86_64-3.8/wordcloud/_version.py\n",
      "    set build/lib.macosx-10.9-x86_64-3.8/wordcloud/_version.py to '1.8.1'\n",
      "    running build_ext\n",
      "    building 'wordcloud.query_integral_image' extension\n",
      "    creating build/temp.macosx-10.9-x86_64-3.8\n",
      "    creating build/temp.macosx-10.9-x86_64-3.8/wordcloud\n",
      "    x86_64-apple-darwin13.4.0-clang -fno-strict-aliasing -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O3 -Wall -Wstrict-prototypes -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O3 -pipe -fdebug-prefix-map=${SRC_DIR}=/usr/local/src/conda/${PKG_NAME}-${PKG_VERSION} -fdebug-prefix-map=/opt/anaconda3/envs/learn-env=/usr/local/src/conda-prefix -flto -Wl,-export_dynamic -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O3 -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -isystem /opt/anaconda3/envs/learn-env/include -D_FORTIFY_SOURCE=2 -mmacosx-version-min=10.9 -isystem /opt/anaconda3/envs/learn-env/include -I/opt/anaconda3/envs/learn-env/include/python3.8 -c wordcloud/query_integral_image.c -o build/temp.macosx-10.9-x86_64-3.8/wordcloud/query_integral_image.o\n",
      "    clang-10: warning: -Wl,-export_dynamic: 'linker' input unused [-Wunused-command-line-argument]\n",
      "    wordcloud/query_integral_image.c:15710:3: warning: 'tp_print' is deprecated [-Wdeprecated-declarations]\n",
      "      0, /*tp_print*/\n",
      "      ^\n",
      "    /opt/anaconda3/envs/learn-env/include/python3.8/cpython/object.h:260:5: note: 'tp_print' has been explicitly marked deprecated here\n",
      "        Py_DEPRECATED(3.8) int (*tp_print)(PyObject *, FILE *, int);\n",
      "        ^\n",
      "    /opt/anaconda3/envs/learn-env/include/python3.8/pyport.h:515:54: note: expanded from macro 'Py_DEPRECATED'\n",
      "    #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__))\n",
      "                                                         ^\n",
      "    wordcloud/query_integral_image.c:15829:3: warning: 'tp_print' is deprecated [-Wdeprecated-declarations]\n",
      "      0, /*tp_print*/\n",
      "      ^\n",
      "    /opt/anaconda3/envs/learn-env/include/python3.8/cpython/object.h:260:5: note: 'tp_print' has been explicitly marked deprecated here\n",
      "        Py_DEPRECATED(3.8) int (*tp_print)(PyObject *, FILE *, int);\n",
      "        ^\n",
      "    /opt/anaconda3/envs/learn-env/include/python3.8/pyport.h:515:54: note: expanded from macro 'Py_DEPRECATED'\n",
      "    #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__))\n",
      "                                                         ^\n",
      "    wordcloud/query_integral_image.c:16090:3: warning: 'tp_print' is deprecated [-Wdeprecated-declarations]\n",
      "      0, /*tp_print*/\n",
      "      ^\n",
      "    /opt/anaconda3/envs/learn-env/include/python3.8/cpython/object.h:260:5: note: 'tp_print' has been explicitly marked deprecated here\n",
      "        Py_DEPRECATED(3.8) int (*tp_print)(PyObject *, FILE *, int);\n",
      "        ^\n",
      "    /opt/anaconda3/envs/learn-env/include/python3.8/pyport.h:515:54: note: expanded from macro 'Py_DEPRECATED'\n",
      "    #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__))\n",
      "                                                         ^\n",
      "    wordcloud/query_integral_image.c:16236:3: warning: 'tp_print' is deprecated [-Wdeprecated-declarations]\n",
      "      0, /*tp_print*/\n",
      "      ^\n",
      "    /opt/anaconda3/envs/learn-env/include/python3.8/cpython/object.h:260:5: note: 'tp_print' has been explicitly marked deprecated here\n",
      "        Py_DEPRECATED(3.8) int (*tp_print)(PyObject *, FILE *, int);\n",
      "        ^\n",
      "    /opt/anaconda3/envs/learn-env/include/python3.8/pyport.h:515:54: note: expanded from macro 'Py_DEPRECATED'\n",
      "    #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__))\n",
      "                                                         ^\n",
      "    4 warnings generated.\n",
      "    x86_64-apple-darwin13.4.0-clang -bundle -undefined dynamic_lookup -Wl,-pie -Wl,-headerpad_max_install_names -Wl,-dead_strip_dylibs -Wl,-rpath,/opt/anaconda3/envs/learn-env/lib -L/opt/anaconda3/envs/learn-env/lib -flto -Wl,-export_dynamic -Wl,-pie -Wl,-headerpad_max_install_names -Wl,-dead_strip_dylibs -Wl,-rpath,/opt/anaconda3/envs/learn-env/lib -L/opt/anaconda3/envs/learn-env/lib -Wl,-pie -Wl,-headerpad_max_install_names -Wl,-dead_strip_dylibs -Wl,-rpath,/opt/anaconda3/envs/learn-env/lib -L/opt/anaconda3/envs/learn-env/lib -march=core2 -mtune=haswell -mssse3 -ftree-vectorize -fPIC -fPIE -fstack-protector-strong -O2 -pipe -isystem /opt/anaconda3/envs/learn-env/include -D_FORTIFY_SOURCE=2 -mmacosx-version-min=10.9 -isystem /opt/anaconda3/envs/learn-env/include -arch x86_64 build/temp.macosx-10.9-x86_64-3.8/wordcloud/query_integral_image.o -o build/lib.macosx-10.9-x86_64-3.8/wordcloud/query_integral_image.cpython-38-darwin.so\n",
      "    ld: warning: -pie being ignored. It is only used when linking a main executable\n",
      "    ld: unsupported tapi file type '!tapi-tbd' in YAML file '/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/lib/libSystem.tbd' for architecture x86_64\n",
      "    clang-10: error: linker command failed with exit code 1 (use -v to see invocation)\n",
      "    error: command 'x86_64-apple-darwin13.4.0-clang' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /opt/anaconda3/envs/learn-env/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-install-bco4t3mn/wordcloud/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-install-bco4t3mn/wordcloud/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/42/259ry5wd5lz2n7nj0kcrvw2h0000gn/T/pip-record-yaf7sxhp/install-record.txt --single-version-externally-managed --compile --install-headers /opt/anaconda3/envs/learn-env/include/python3.8/wordcloud Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T04:24:42.641816Z",
     "start_time": "2022-02-04T04:24:42.269884Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-021e0a03a31f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-04T04:33:11.207973Z",
     "start_time": "2022-02-04T04:33:11.028395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9093 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/tweet_product.csv', encoding= 'unicode_escape')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "## Text Preprocessing Approach\n",
    "\n",
    "Describe and justify the process for preparing the data for analysis.\n",
    "\n",
    "* Removed @mentions, links, non-ASCII characters, and words consisting of only numbers\n",
    "* Generated several stopwords lists using NLTK's list as the baseline\n",
    "* Evaluated several different methods for generating frequency in Documemt Term Matrix: binary, count, and count with Tf-Idf normalization\n",
    "* Tried using uni-grams, uni-grams + bi-grams, and just bi-grams\n",
    "* Tested with and without applying stemming and lemmatization using NLTK\n",
    "* Testing using original data with imbalanced classes as well as randomly oversampled data\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* Were there variables you dropped or created?\n",
    "* How did you address missing values or outliers?\n",
    "* Why are these choices appropriate given the data and the business problem?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-03T01:39:06.980414Z",
     "start_time": "2022-02-03T01:39:06.965210Z"
    }
   },
   "outputs": [],
   "source": [
    "# FreqDist viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our EDA, we looked at tweets with positive and negative sentiments as a whole as well as on a company and product level to answer the questions mentioned in the introduction section. Wordclouds were generated for each analysis. To be able to produce these graphics the tweets were tokenized with nltk's TweetTokenizer since it has built-in functionality for tweets specifically, lemmatized with the WordNetLemmatizer and stop words were removed from these tokens. We customized stop words to get a better view of the content of the tweets for addressing the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling\n",
    "Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "Our modelling process was split in two: Binary Classification and Multiclass Classification. For each type of classification, data was prepared and a baseline dummy classifier model was trained to serve as a baseline. For comparison we trained/tested Random Forest models and Logistic Regression models for Multiclass Classification while adding on Multinomial Naive Bayes for the Binary Classification on top of these.\n",
    "\n",
    "We evaluated each model and tuned hyperparameters with gridsearches that optimized for the recall macro scores since we wanted the models to correctly classify all classes. These steps were repeated after data was randomly oversampled.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* How did you analyze or model the data?\n",
    "* How did you iterate on your initial approach to make it better?\n",
    "* Why are these choices appropriate given the data and the business problem?\n",
    "***\n",
    "\n",
    "Tested Naive Bayes (Multinomial), Random Forest, and Logistic Regression classifiers\n",
    "To determine optimal preprocessing steps, model type, and model hyperparameters, ran grid searches optimized for recall macro\n",
    "Evaluated both binary (positive and negative) and multi-class (positive, negative, and no emotion) classification. Compared the all-in-one multi-class model to the performance if we used multi-class as the first pass, and the binary model as the second pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model for both binary and muli-class classification problems were both Logistic Regression. The models agreed on most preprocessing and model hyperparameters, but differed in a few ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model achieved ~60-65% balanced accuracy across all classes on unseen test data\n",
    "~30% better than guessing randomly based on class distribution\n",
    "Identified about the same percentage of True Positives for any class, although confused Positive and No Sentiment more often than either of these with Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model achieved ~75% balanced accuracy across both classes on unseen test data\n",
    "~25% better than guessing randomly based on class distribution\n",
    "Better at predicting positive sentiment than negative: only ~10-15% of Positives misclassified as Negative, while ~30-40% of Negatives misclassified as Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "The winner of this task was the tuned oversampled logistic regression model with a recall macro score of 0.62. The tuned random oversampled logistic regression model also scored the same 0.62; however, since it got to the same score only after the random oversampling we are declaring the non-oversampled model as the winner.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* How do you interpret the results?\n",
    "* How well does your model fit your data? How much better is this than your baseline model?\n",
    "* How confident are you that your results would generalize beyond the data you have?\n",
    "* How confident are you that this model would benefit the business if put into use?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word clouds generated from top predictors of Positive and Negative sentiment seemed to capture the emotions fairly well. Ultimately, SMEs would need to weigh in on whether reviewing samples of tweets based on these predictors provided insights they didn't already have from other sources of customer sentiment.\n",
    "\n",
    "Just from having read through some sample tweets during my EDA and preprocessing, I was able to glean some basic themes around what people were tweeting positively about and what they were tweeting negatively about.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, SXSW attendees sounded pretty positive about the new iPad 2, which was newly released at the time. Apple also had a pop-up store in downtown Austin that garnered a lot of chatter: some positive, but also some negative because people were annoyed at having to wait in long line to enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People expressed frustration about the battery life of their phones, as well as certain apps which had been designed to run on iOS or Android.\n",
    "\n",
    "One of the biggest challenges would be determining a reasonable way to review the full text of tweets with certain themes to try to determine actionable insights. For example, I'm not surprised that words such as \"cool\" and \"free\" were top predictors of positive sentiment, but we would need to know exactly what people thought was \"cool\" and what \"free\" things they liked most.\n",
    "\n",
    "SMEs, especially those who were familiar with what events were hosted and what merchandise was given away for free, would certainly need to interpret these further. Separating tweets into posisitve, negative, and neutral would only be the first step: reviewing the tweets themselves to determine themes in positive and negative sentiment would also be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS & RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* What would you recommend the business do as a result of this work?\n",
    "* What are some reasons why your analysis might not fully solve the business problem?\n",
    "* What else could you do in the future to improve this project?\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "As a proof-of-concept, I demonstrated that even simple models such as Logistic Regression can be trained on labeled data to predict sentiment more accurately than random guessing.\n",
    "\n",
    "Since the Logistic Regression models are easy to interpret, I think they could provide useful insights for business stakeholders at a company looking to inform marketing and product strategies. My recommended approach would be to use the multi-class model to separate positive and negative tweets, and use the binary model as a second step to pull out the most important predictors of each sentiment.\n",
    "\n",
    "Although these simple models only give us feature importances of n-grams, if we built a simple tool to search for each n-gram as a keyword in tweets, we could pull samples for subject matter experts to review and interpret before determining any next steps.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "Today, it is more important than ever for businesses to be in tune with their customers. \"Listening\" to the public opinion on their products and services not only allows for them to maintain financial success, but also provides them with opportunities to stay competitive in the market. To sum up, our analysis showed the following:\n",
    "\n",
    "1. How is Apple perceived as a company during the SXSW Conference, and how does this compare to Google as one of their main competitors?\n",
    "\n",
    "During the SXSW Conference, 81.1% of all tweets related to Apple were positive compared to Google's 82%.\n",
    "During the SXSW Conference, 16.1% of all tweets related to Apple were negative compared to Google's 14.9%\n",
    "This suggests that both companies and their products and services are perceived mostly in a positive way.\n",
    "\n",
    "2. How are Apple and Google's products and announcements perceived during the SXSW Conference? Are there specific pain points within the products that Apple should address?\n",
    "\n",
    "Apple - Positives:\n",
    "\n",
    "Tweets about Apple suggest that the temporary pop-up store announcement in downtown Austin has been received very well by Apple fans and generated a lot of excitement for the brand.\n",
    "One of the most frequently talked about products was the iPad 2 which seems to have been launched during SXSW and sold in the Austin temporary pop-up store. Based on the tweets, Apple's launch of this product definitely generated a lot of buzz.\n",
    "Samplers and free products/services were frequently mentioned as well.\n",
    "Apple - Negatives:\n",
    "\n",
    "The iPhone's battery is frequently discussed in negative tweets.\n",
    "Design of the iPad was referred to as a \"design headache.\"\n",
    "There are several tweets mentioning Kara Swisher and references to Apple as a \"fascist company.\"\n",
    "Several apps are referred to as \"battery killer\" and the design of the News app seems to have not been received positively.\n",
    "Google - Positives:\n",
    "\n",
    "Google's party in Lustre Pearl generated a lot of buzz.\n",
    "Marissa Mayer is mentioned extensively, so her talk was positively received.\n",
    "Google's new social network project \"Circle\" seems to have caused a lot of excitement.\n",
    "Microsoft's Bing search engine is mentioned in a negative way.\n",
    "Google - Negatives:\n",
    "\n",
    "Some users seem to be having issues with Android OS based on words such as \"buggy\", \"replaced\", and \"painful.\"\n",
    "Samsung is mentioned in tweets with relation to Android suggesting some users may prefer it to Google's products.\n",
    "Users of Meetup are having problems with Android."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In light of the insights we provided above, our recommendations for Apple are as follows:\n",
    "\n",
    "Users are not happy with iPhone's battery performance and therefore more R&D in this area may be needed.\n",
    "Some users also don't seem to like the iPad's design. It may be fruitful to look more into this issue and potentially conduct a survey with users to understand the downsides of the current design.\n",
    "Users seem to be having several issues with Android apps. This may be a great opportunity for Apple to make sure these issues don't exist in iOS and market their products to these users.\n",
    "The marketing strategy for the new pop-up store seems to have been successful. It can be employed in conjuction with other conferences or major events.\n",
    "Based on the response to Google's party, it may be effective to throw a party during the next SXSW Conference to generate excitement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we used was a crowdsourced dataset which brings about certain challenges, one of which is that labeling tweets as \"Positive\", \"Negative\" or \"No emotion\" can be a highly subjective exercise. What I may think is a positive tweet, someone else may interpret as negative. Additionally, the context of these tweets matter. Since we don't know the methodology of how the data was labeled, there could have been human error in labeling where a tweet that was intended to be sarcastic can be labeled incorrectly for example. This would negatively impact the quality of the data.\n",
    "\n",
    "Furthermore, our dataset consisted of 9,092 tweets which is a fairly small number. After removing neutral tweets we were only left with around 3,000 tweets for the binary classification. So, the amount of data used was limited. Additionally, the class imbalance was pretty significant with approximately 61% of data being neutral, 33% being positive and 6% being negative. Arguably, the \"Negative\" class would be much more important than the \"Neutral\" class in trying to understand where the areas of improvement are for Apple in general.\n",
    "\n",
    "As next steps, if Apple would like to generalize these models for different applications, we would definitely gather more data from Twitter and potentially other sources. Additionally, if the data had to be labeled by humans, we would set guidelines for what each class of tweet would consist of with examples to make sure that the labels didn't solely rely on emotions. Furthermore, taking the average of sentiment labels for each tweet would result in more accurate labels.\n",
    "\n",
    "Lastly, the performance of the models could be greatly improved by rethinking this project with Neural Networks. In the future we would use Deep NLP to classify tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
